\documentclass[12pt]{book}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{mathtools}
\usepackage{amsmath}
\begin{document}
\title{\textit{Networks:  An Introduction} Research Notes}
\author{W. J. Cunningham}
\maketitle

\setcounter{chapter}{5}
\chapter{Mathematics of Networks}

\section{Networks and Their Representation}
Terminology:
\begin{itemize}
  \item Network/Graph
  \item Vertex/Node/Site/Actor
  \item Edge/Link/Bond/Tie
\end{itemize}
The number of vertices is denoted by $n$ and the number of edges by $m$.

\section{The Adjacency Matrix}
If we denote an edge between vertices $i$ and $j$ by $(i,j)$ then the complete network can be specified by giving the value of $n$ and a list of all the edges.  Such a specification is called an \textit{edge list}.  A better representation of a network is the \textit{adjacency matrix}.  The diagonal elements are all zero and it is symmetric for simple undirected graphs.  The elements are defined such that

\begin{equation}
A_{ij} = 
  \begin{cases}
    1$ if there is an edge between vertices $i$ and $j, \\
    0$ otherwise$.
  \end{cases}
\end{equation}

\section{Weighted Networks}
In some situations it is useful to represent edges as having a strength, weight, or value.  Such \textit{weighted networks} can be represented by giving the elements of the adjacency matrix values equal to the weights of the corresponding connections.  Vertices can also have weights.

\section{Directed Networks}
A \textit{directed network} is a network in which each edge has a direction, pointing \textit{from} one vertex \textit{to} another.  Such edges are called \textit{directed edges}.  The adjacency matrix of a directed network has the matrix elements

\begin{equation}
A_{ij} = 
  \begin{cases}
    1$ if there is an edge \textit{from j to i}$, \\
    0$ otherwise$.
  \end{cases}
\end{equation}

Note that the direction indicates the edge runs \textit{from} the second index \textit{to} the first. 

We can think of undirected networks as directed networks in which each undirected edge has been replaced with two directed ones running in opposite directions between the same pair of vertices.  The adjacency matrix for such a network is then symmetric and exactly the same as for the original undirected network.

\subsection{Cocitation and Bibliographic Coupling}
A directed network may be transformed into an undirected one in one of the following ways:
\begin{enumerate}
  \item Ignore the edge directions entirely
  \item Use \textit{cocitation} (do this one!)
\end{enumerate}
The \textit{cocitation} of two vertices $i$ and $j$ in a directed network is the number of vertices that have outgoing edges pointing to both $i$ and $j$:

\begin{equation}
C_{ij} = \sum\limits_{k=1}^n A_{ik}A_{jk} = \sum\limits_{k=1}^n A_{ik}A_{kj}^T
\end{equation}

We can also define the (symmetric) \textit{cocitation matrix} \textbf{C} to be the $n \times n$ matrix with elements $C_{ij}$:

\begin{equation}
\mathbf{C}=\mathbf{AA}^T
\end{equation}

This allows for us to build a \textit{cocitation network}.  This network conventionally has no self-edges.  We can make it a weighted network by identifying vertex pairs cited by more common neighbors as having a stronger connection than those cited by fewer.  This matrix plays a similar role to the adjacency matrix for this network. \\

The \textit{bibliographic coupling} of two vertices in a directed network is the number of other vertices to which both point.  The bibliographic coupling of $i$ and $j$ is given by

\begin{equation}
B_{ij} = \sum\limits_{k=1}^n A_{ki}A_{kj} = \sum\limits_{k=1}^n A_{ik}^TA{kj},
\end{equation}

and we define the (symmetric) \textit{bibliographic coupling matrix} \textbf{B} to be the $n \times n$ matrix with elements $B_{ij}$ so that

\begin{equation}
\mathbf{B} = \mathbf{A}^T\mathbf{A}
\end{equation}

In general, bibliographic coupling is a more uniform indicator of similarity between papers than cocitation.  It also does not change over time, so it is a static variable.

\subsection{Acyclic Directed Networks}
A \textit{cycle} in a directed network is a closed loop of edges with the arrows on each of the edges pointing the same way around the loop.  Networks which have no cycles are called \textit{acyclic} networks, and ones with cycles are called \textit{cyclic}.  \textbf{Causal networks are necessarily acyclic}. \\
In acyclic networks there must be at least one vertex somewhere on the network that has ingoing edges only and no outgoing ones.  A simple algorithm for determining whether a network is acyclic is:
\begin{enumerate}
  \item Find a vertex with no outgoing edges.
  \item If no such vertex exists, the network is \textit{cyclic}.  Otherwise, if such a vertex does exist, remove it and all its ingoing edges from the network.
  \item If all vertices have been removed, the network is \textit{acyclic}.  Otherwise go back to step 1.
\end{enumerate}

In the case that the network is acyclic, the adjacency matrix is an upper triangular matrix.  For every acyclic directed network there exists at least one labeling of the vertices such that the adjacency matrix will be strictly upper triangular.  Further, all of its eigenvalues will be zero, so it will be a \textit{nilpotent matrix}.

\section{Hypergraphs}
These networks have links which join more than two vertices at a time (probably not useful for causal networks).

\section{Bipartite Networks}
These networks have two kinds of vertices (probably not useful for causal networks).

\section{Trees}
A \textit{tree} is a connected, undirected network which contains no closed loops.  If all parts of a network are trees, the complete network is called a \textit{forest}.  Topologically, a tree has no particular root, but in some applications there are other reasons for designating a root.  In trees, there is exactly one path between any pair of nodes, and a tree of $n$ vertices always has $n-1$ edges.

\section{Planar Networks}
A \textit{planar network} is a network that can be drawn on a plane without having any edges cross.  Any network that contains a subset or expansion of vertices (or subgraph) in the form of $K_5$ or $UG$ is non-planar.  The converse is true by \textit{Kuratowski's Theorem}.  Real-world networks are rarely precisely planar.  No widely accepted metric for degree of planarity has emerged.

\section{Degree}
The \textit{degree} of a vertex in a graph is the number of edges connected to it.  For an undirected graph of $n$ vertices the degree can be written in terms of the adjacency matrix as

\begin{equation}
k_i = \sum\limits_{j=1}^n A_{ij}
\end{equation}

The number of edges is equal to the sum of the degrees of all the vertices, so

\begin{equation}
2m = \sum\limits_{i=1}^n k_i
\end{equation}

The mean degree $c$ of a vertex in an undirected graph is

\begin{equation}
c = \frac{1}{n} \sum\limits_{i=1}^n k_i = \frac{2m}{n}
\end{equation}

The maximum possible number of edges in a simple graph is $\binom{n}{2} = \frac{1}{2}n(n-1)$.  The \textit{connectance} or \textit{density} $\rho$ of the graph is the fraction of edges that are actually present.

\begin{equation}
\rho = \frac{m}{\binom{n}{2}} = \frac{2m}{n(n-1)} = \frac{c}{n-1} \approx \frac{c}{n}
\end{equation}

A network for which the density $\rho$ tends to a constant as $n \rightarrow \infty$ is said to be \textit{dense}.  A network for which $\rho \rightarrow 0$ as $n \rightarrow \infty$ is said to be \textit{sparse}.  In particular, a network is sparse if $c$ tends to a constant as $n$ becomes large.  \textbf{Causal networks are sparse networks}. \\

In directed networks each vertex has two degrees.  The \textit{in-degree} is the number of ingoing edges connected to a vertex and the \textit{out-degree} is the number of outgoing edges.  If there is an edge from $j$ to $i$, these quantities can be written

\begin{equation}
k_i^{\textrm{in}} = \sum\limits_{j=1}^n A_{ij},
\end{equation}

\begin{equation}
k_j^{\textrm{out}} = \sum\limits_{i=1}^n A_{ij}.
\end{equation}

The mean in-degree $c_{\textrm{in}}$ and the mean out-degree $c_{\textrm{out}}$ of every directed network are equal:

\begin{equation}
c_{\textrm{in}} = \frac{1}{n} \sum\limits_{i=1}^n k_i^{\textrm{in}} = \frac{1}{n} \sum\limits_{j=1}^n k_j^{\textrm{out}} = c_{\textrm{out}}
\end{equation}

We can denote both by the variable $c$ so that

\begin{equation}
c=\frac{m}{n}
\end{equation}

\section{Paths}
A \textit{path} is any sequence of vertices such that every consecutive pair of vertices in the sequence is connected by an edge in the network. \textit{Self-avoiding paths} are more important - Hamiltonian and geodesic paths are two special cases.  The \textit{length} of a path in a network is the number of edges traversed along the path.  The number of paths of length $r$ from vertex $j$ to vertex $i$ is given by

\begin{equation}
N_{ij}^{(r)} = \left[\mathbf{A}^r\right]_{ij}
\end{equation}

and the number of loops of length $r$ is given by

\begin{equation}
\begin{split}
L_r &= \sum_{i=1}^n \left[\mathbf{A}^r\right]_{ii} \\
    &= \mathrm{Tr}\mathbf{A}^r \\
    &= \sum_i \kappa_i^r
\end{split}
\end{equation}

where $\kappa_i$ are the eigenvalues of the adjacency matrix.  Note that for a directed graph, the adjacency matrix is asymmetric and therefore may have complex eigenvalues.

\subsection{Geodesic Paths}
A \textit{geodesic path} is a path between two vertices such that no shorter path exists.  These paths are necessarily self-avoiding, though they are not necessarily unique.  The \textit{diameter} of a graph is the length of the longest geodesic path between any pair of vertices in the network for which a path actually exists.

\subsection{Eulerian and Hamiltonian Paths}
An \textit{Eulerian path} is a path which traverses each edge in a network exactly once.  A \textit{Hamiltonian path} is a path that visits each vertex only once.

\section{Components}
The disconnected subgroups of a network are called \textit{components}.  The adjacency matrix of a network with more than one component can be written in block diagonal form.

\section{Independent Paths, Connectivity, and Cut Sets}
The number of independent paths between given vertices gives a simple measure of how strongly the vertices are connected to one another.  The number of independent paths cannot exceed the number of edges in the network.  The number of independent paths between a pair of vertices is called the \textit{connectivity} of the vertices.  A \textit{cut set} is a set of vertices whose removal will disconnect a specified pair of vertices.  A \textit{minimum cut set} is the smallest cut set that will disconnect a specified pair of vertices. \\

\textit{Menger's Theorem} states that if there is not cut set of size less than $n$ between a given pair of vertices, then there are at least $n$ independent paths between the same vertices.  It implies that the size of the minimum vertex cut set that disconnects a given pair of vertices in a network is equal to the vertex connectivity of the same vertices.

\section{The Graph Laplacian}
\subsection{Diffusion}
The diffusion equation is

\begin{equation}
\frac{\mathrm d\psi_i}{\mathrm dt} = C\sum_j A_{ij}\left(\psi_j - \psi_i\right)
\end{equation}

We can now define the \textit{graph Laplacian} as

\begin{equation}
\mathbf{L} = \mathbf{D} - \mathbf{A}
\end{equation}

where $\mathbf{D}$ is the diagonal matrix of vertex degrees and $\mathbf{A}$ is the adjacency matrix.  The elements of this matrix are

\begin{equation}
L_{ij} = \begin{cases}
  k_i & \mbox{if} \,\, i = j \\
  -1  & \mbox{if} \,\, i \neq j \mbox{and there is an edge} \,\, (i,j) \\
  0   & \mbox{otherwise}
\end{cases}
\end{equation}

This becomes an eigenvector equation $\mathbf{Lv}_i = \lambda_i\mathbf{v}_i$, with the solution

\begin{equation}
a_i(t) = a_i(0)e^{-C\lambda_i t}
\end{equation}

where $C$ is the \textit{diffusion constant}.

\subsection{Eigenvalues of the Graph Laplacian}
Because the Laplacian is a symmetric matrix, its eigenvalues are real

\end{document}
